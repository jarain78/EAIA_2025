{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\">\n",
        "  <b>Divide and Learn: The Future of Distributed AI</b>\n",
        "</p>"
      ],
      "metadata": {
        "id": "99cBGl5vZS7S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# ðŸ©» Federated Learning with Flower (FL) on Mammography Images\n",
        "\n",
        "\n",
        "```\n",
        "MyDrive/mammo_data/\n",
        " â”œâ”€â”€ Benign/\n",
        " â”‚    â”œâ”€â”€ image_001.png\n",
        " â”‚    â””â”€â”€ ...\n",
        " â””â”€â”€ Malignant/\n",
        "      â”œâ”€â”€ image_101.png\n",
        "      â””â”€â”€ ...\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "PGvfyGHwMFOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Install dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "yyClaZRdGfen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install flwr\n",
        "#!pip install \"flwr>=1.7,<2.0\"\n",
        "# Instala versiones compatibles para Colab\n",
        "!pip -q install \"flwr>=1.7,<2.0\" \"ray[default]>=2.9,<3.0\"\n",
        "\n",
        "import ray\n",
        "# InicializaciÃ³n bÃ¡sica; baja recursos para Colab si quieres\n",
        "ray.shutdown()\n",
        "ray.init(ignore_reinit_error=True, include_dashboard=False, num_cpus=2)\n",
        "print(\"Ray OK:\", ray.is_initialized())\n",
        "\n",
        "!pip install -U \"flwr[simulation]\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgT5ZtYXGpVk",
        "outputId": "f1cff41d-0284-485b-f2dc-6aa50afa8df0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-30 11:30:11,806\tINFO worker.py:1771 -- Started a local Ray instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ray OK: True\n",
            "Requirement already satisfied: flwr[simulation] in /usr/local/lib/python3.12/dist-packages (1.22.0)\n",
            "Requirement already satisfied: click<8.2.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (8.1.8)\n",
            "Requirement already satisfied: cryptography<45.0.0,>=44.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (44.0.3)\n",
            "Requirement already satisfied: grpcio!=1.65.0,<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.75.0)\n",
            "Requirement already satisfied: grpcio-health-checking<2.0.0,>=1.62.3 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.62.3)\n",
            "Requirement already satisfied: iterators<0.0.3,>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.0.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.0.2)\n",
            "Requirement already satisfied: pathspec<0.13.0,>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.12.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (4.25.8)\n",
            "Requirement already satisfied: pycryptodome<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (3.23.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (6.0.2)\n",
            "Requirement already satisfied: ray==2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.31.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.32.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.5.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (13.9.4)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (2.2.1)\n",
            "Requirement already satisfied: tomli-w<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (1.2.0)\n",
            "Requirement already satisfied: typer<0.13.0,>=0.12.5 in /usr/local/lib/python3.12/dist-packages (from flwr[simulation]) (0.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (3.19.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (25.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (1.4.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.12/dist-packages (from ray==2.31.0->flwr[simulation]) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.65.0,<2.0.0,>=1.62.3->flwr[simulation]) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->flwr[simulation]) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<14.0.0,>=13.5.0->flwr[simulation]) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.13.0,>=0.12.5->flwr[simulation]) (1.5.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<45.0.0,>=44.0.1->flwr[simulation]) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.5.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray==2.31.0->flwr[simulation]) (0.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 2 â€” Configuration and dataset utilities\n"
      ],
      "metadata": {
        "id": "KzknC9vDGk-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, shutil, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "\n",
        "import kagglehub\n"
      ],
      "metadata": {
        "id": "D6m35VogOKKU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== MAIN CONFIGURATION ====\n",
        "USE_GOOGLE_DRIVE = False          # Change to False if you donâ€™t want to mount Drive\n",
        "ROOT_RELATIVE = \"mammo_data\"     # Root dataset folder (inside Drive or local)\n",
        "NUM_CLIENTS = 3                  # Number of federated clients\n",
        "IMG_SIZE = (256, 256)            # Resize images to this size\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS_LOCAL = 1                 # Local epochs per round\n",
        "ROUNDS = 3                       # Federated rounds\n",
        "VAL_SPLIT = 0.2                  # Validation split ratio per client\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"awsaf49/cbis-ddsm-breast-cancer-image-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    DATA_ROOT = Path(\"/content/drive/MyDrive\") / ROOT_RELATIVE\n",
        "else:\n",
        "    DATA_ROOT = Path(\"/content\") / ROOT_RELATIVE\n",
        "\n",
        "\n",
        "print(\"DATA_ROOT:\", DATA_ROOT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L1gWDm5Onga",
        "outputId": "e98b226e-9f2d-49c3-8f07-e0a2e9f3db0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'cbis-ddsm-breast-cancer-image-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/cbis-ddsm-breast-cancer-image-dataset\n",
            "DATA_ROOT: /content/mammo_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbOqHmBoGNrw",
        "outputId": "95ef702f-4677-4f26-834b-a2d81217ec77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Found dataset folders: ['Malignant', 'Benign']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ==== TRANSFORMS ====\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# ==== DEMO DATASET CREATOR ====\n",
        "def create_demo_mammo_dataset(root: Path, n_per_class=60):\n",
        "    \"\"\"\n",
        "    Create a minimal synthetic dataset with 2 classes: Benign / Malignant.\n",
        "    Only for testing Flower end-to-end without big downloads.\n",
        "    \"\"\"\n",
        "    classes = [\"Benign\", \"Malignant\"]\n",
        "    for cls in classes:\n",
        "        (root/cls).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    W, H = IMG_SIZE\n",
        "    for cls in classes:\n",
        "        for i in range(n_per_class):\n",
        "            img = Image.new(\"L\", (W, H), color=0)\n",
        "            if cls == \"Benign\":\n",
        "                # Smooth circular patterns\n",
        "                for _ in range(6):\n",
        "                    cx, cy = random.randint(0,W-1), random.randint(0,H-1)\n",
        "                    r = random.randint(10, 35)\n",
        "                    for y in range(max(0,cy-r), min(H, cy+r)):\n",
        "                        for x in range(max(0,cx-r), min(W, cx+r)):\n",
        "                            if (x-cx)**2 + (y-cy)**2 <= r*r:\n",
        "                                img.putpixel((x,y), min(255, img.getpixel((x,y)) + random.randint(15,25)))\n",
        "                img = img.filter(ImageFilter.GaussianBlur(1.5))\n",
        "            else:\n",
        "                # Hard edges / bright masses\n",
        "                for _ in range(5):\n",
        "                    x0, y0 = random.randint(0,W-30), random.randint(0,H-30)\n",
        "                    w, h = random.randint(15,45), random.randint(15,45)\n",
        "                    for y in range(y0, min(H, y0+h)):\n",
        "                        for x in range(x0, min(W, x0+w)):\n",
        "                            img.putpixel((x,y), min(255, img.getpixel((x,y)) + random.randint(25,35)))\n",
        "                img = ImageOps.autocontrast(img)\n",
        "            img.save(root/cls/f\"{cls}_{i:03d}.png\")\n",
        "\n",
        "# Create demo data if missing\n",
        "if not DATA_ROOT.exists() or not any((DATA_ROOT/\"Benign\").glob(\"*\")) or not any((DATA_ROOT/\"Malignant\").glob(\"*\")):\n",
        "    print(\"No real dataset found â†’ creating synthetic DEMO at:\", DATA_ROOT)\n",
        "    create_demo_mammo_dataset(DATA_ROOT, n_per_class=60)\n",
        "else:\n",
        "    print(\"âœ… Found dataset folders:\", [p.name for p in DATA_ROOT.iterdir()])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 3 â€” Stratified partition per client and DataLoaders\n"
      ],
      "metadata": {
        "id": "vuGahYAALySB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the whole dataset as ImageFolder\n",
        "full_dataset = datasets.ImageFolder(str(DATA_ROOT), transform=transform_train)\n",
        "class_to_idx = full_dataset.class_to_idx\n",
        "print(\"Classes:\", class_to_idx, \"Total images:\", len(full_dataset))\n",
        "\n",
        "# Indices per class\n",
        "from collections import defaultdict\n",
        "indices_by_class = defaultdict(list)\n",
        "for idx, (_, target) in enumerate(full_dataset.samples):\n",
        "    indices_by_class[target].append(idx)\n",
        "\n",
        "# Stratified partition across NUM_CLIENTS\n",
        "def stratified_partition(indices_by_class, num_clients):\n",
        "    parts = [[] for _ in range(num_clients)]\n",
        "    for c, idxs in indices_by_class.items():\n",
        "        random.shuffle(idxs)\n",
        "        chunk = math.ceil(len(idxs)/num_clients)\n",
        "        for i in range(num_clients):\n",
        "            parts[i].extend(idxs[i*chunk:(i+1)*chunk])\n",
        "    return parts\n",
        "\n",
        "client_indices = stratified_partition(indices_by_class, NUM_CLIENTS)\n",
        "\n",
        "# Build loaders per client (train/val)\n",
        "def make_client_loaders(indices, val_split=VAL_SPLIT, batch_size=BATCH_SIZE):\n",
        "    subset = Subset(full_dataset, indices)\n",
        "    n = len(subset)\n",
        "    n_val = int(n*val_split)\n",
        "    n_train = n - n_val\n",
        "    train_subset, val_subset = random_split(\n",
        "        subset, [n_train, n_val],\n",
        "        generator=torch.Generator().manual_seed(SEED)\n",
        "    )\n",
        "    # Different transforms for train/val\n",
        "    train_subset.dataset.transform = transform_train\n",
        "    val_subset.dataset.transform = transform_val\n",
        "\n",
        "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    return train_loader, val_loader\n",
        "\n",
        "client_loaders = [make_client_loaders(idxs) for idxs in client_indices]\n",
        "for i,(tr,va) in enumerate(client_loaders):\n",
        "    print(f\"Client {i}: train={len(tr.dataset)} | val={len(va.dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OTwvcJKHvLT",
        "outputId": "e6108329-8d70-4126-da6a-3ca1324b49ca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {'Benign': 0, 'Malignant': 1} Total images: 120\n",
            "Client 0: train=32 | val=8\n",
            "Client 1: train=32 | val=8\n",
            "Client 2: train=32 | val=8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 4 â€” CNN model\n",
        "\n"
      ],
      "metadata": {
        "id": "tHfboga1L5D7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MammoCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1-channel input (grayscale)\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.bn1   = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.bn2   = nn.BatchNorm2d(32)\n",
        "        self.pool  = nn.MaxPool2d(2,2)\n",
        "        self.drop  = nn.Dropout(0.3)\n",
        "        # IMG_SIZE 256x256 â†’ after 2 pools â†’ 64x64 with 32 channels\n",
        "        self.fc1   = nn.Linear(32*64*64, 128)\n",
        "        self.fc2   = nn.Linear(128, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.drop(F.relu(self.fc1(x)))\n",
        "        return self.fc2(x)\n"
      ],
      "metadata": {
        "id": "716aq1G-HwQT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 5 â€” Flower client and train/eval functions\n"
      ],
      "metadata": {
        "id": "DG6jm_IjL8kW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import flwr as fl\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from copy import deepcopy\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(images)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss/len(loader) if len(loader) > 0 else 0.0\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, loss_fn):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    for images, labels in loader:\n",
        "        images, labels = images.to(DEVICE, non_blocking=True), labels.to(DEVICE, non_blocking=True)\n",
        "        logits = model(images)\n",
        "        loss = loss_fn(logits, labels)\n",
        "        total_loss += loss.item()\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    acc = correct/total if total > 0 else 0.0\n",
        "    return total_loss/len(loader) if len(loader) > 0 else 0.0, acc\n",
        "\n",
        "# Registry of loaders for each client id\n",
        "CLIENT_REGISTRY = {}\n",
        "for cid,(tr,va) in enumerate(client_loaders):\n",
        "    CLIENT_REGISTRY[str(cid)] = {\"train\": tr, \"val\": va}\n",
        "\n",
        "# Flower client implementation\n",
        "class MammoClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid: str):\n",
        "        self.cid = cid\n",
        "        self.model = MammoCNN().to(DEVICE)\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "        self.train_loader = CLIENT_REGISTRY[cid][\"train\"]\n",
        "        self.val_loader   = CLIENT_REGISTRY[cid][\"val\"]\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [t.detach().cpu().numpy() for _, t in self.model.state_dict().items()]\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        state_dict = deepcopy(self.model.state_dict())\n",
        "        for k, name in enumerate(state_dict.keys()):\n",
        "            state_dict[name] = torch.tensor(parameters[k])\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        last_loss = 0.0\n",
        "        for _ in range(EPOCHS_LOCAL):\n",
        "            last_loss = train_one_epoch(self.model, self.train_loader, self.optimizer, self.loss_fn)\n",
        "        return self.get_parameters({}), len(self.train_loader.dataset), {\"train_loss\": float(last_loss)}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.set_parameters(parameters)\n",
        "        val_loss, val_acc = evaluate(self.model, self.val_loader, self.loss_fn)\n",
        "        # You can report multiple metrics; weâ€™ll aggregate them\n",
        "        return float(val_loss), len(self.val_loader.dataset), {\"val_accuracy\": float(val_acc), \"val_loss\": float(val_loss)}\n",
        "\n",
        "def client_fn(cid: str):\n",
        "    # cid: \"0\" .. \"NUM_CLIENTS-1\"\n",
        "    return MammoClient(cid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQlklZSgH5yv",
        "outputId": "7a1907da-0386-45a1-cec8-f2a7575a1b77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 6 â€” Initialize Ray, FedAvg strategy (with aggregation), and run simulation\n"
      ],
      "metadata": {
        "id": "GJd7NTDsMBvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "import flwr as fl\n",
        "import torch\n",
        "\n",
        "# Init Ray for Flower Simulation (Colab friendly)\n",
        "ray.shutdown()\n",
        "ray.init(ignore_reinit_error=True, include_dashboard=False, num_cpus=2)\n",
        "print(\"Ray OK:\", ray.is_initialized())\n",
        "\n",
        "# Weighted average aggregator for client metrics\n",
        "def weighted_average(metrics: list[tuple[int, dict[str, float]]]) -> dict[str, float]:\n",
        "    # metrics: [(num_examples, {\"val_accuracy\": ..., \"val_loss\": ...}), ...]\n",
        "    if not metrics:\n",
        "        return {}\n",
        "    total_examples = sum(n for n, _ in metrics)\n",
        "    keys = set().union(*(m.keys() for _, m in metrics))\n",
        "    out: dict[str, float] = {}\n",
        "    for k in keys:\n",
        "        out[k] = sum(m.get(k, 0.0) * n for n, m in metrics) / max(total_examples, 1)\n",
        "    return out\n",
        "\n",
        "# Define a single, modern FedAvg strategy (NO legacy EvaluateMetricsAggregator)\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=NUM_CLIENTS,\n",
        "    min_evaluate_clients=NUM_CLIENTS,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # âœ… modern hook\n",
        ")\n",
        "\n",
        "# Run Flower simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=ROUNDS),\n",
        "    strategy=strategy,\n",
        "    client_resources={\n",
        "        \"num_cpus\": 1,\n",
        "        \"num_gpus\": 1.0 if torch.cuda.is_available() else 0.0\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"Done. Check `history` for results.\")\n"
      ],
      "metadata": {
        "id": "HObEJEyVIAGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e714cfa-5a7c-40eb-bf99-267f333c7949"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-30 11:31:04,103\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "WARNING:flwr:DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n",
            "\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n",
            "\n",
            "\t\t$ flwr new  # Create a new Flower app from a template\n",
            "\n",
            "\t\t$ flwr run  # Run the Flower app in Simulation Mode\n",
            "\n",
            "\tUsing `start_simulation()` is deprecated.\n",
            "\n",
            "            This is a deprecated feature. It will be removed\n",
            "            entirely in future versions of Flower.\n",
            "        \n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=3, no round_timeout\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ray OK: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "2025-09-30 11:31:11,918\tINFO worker.py:1771 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'CPU': 8.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'object_store_memory': 16319712460.0, 'memory': 32639424923.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 8 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=11863)\u001b[0m 2025-09-30 11:31:19.585756: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=11863)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "\u001b[36m(pid=11863)\u001b[0m E0000 00:00:1759231879.610396   11863 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=11863)\u001b[0m E0000 00:00:1759231879.617688   11863 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=11863)\u001b[0m W0000 00:00:1759231879.636522   11863 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=11863)\u001b[0m W0000 00:00:1759231879.636587   11863 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=11863)\u001b[0m W0000 00:00:1759231879.636591   11863 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(pid=11863)\u001b[0m W0000 00:00:1759231879.636594   11863 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[36m(pid=11858)\u001b[0m 2025-09-30 11:31:20.048764: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[36m(pid=11858)\u001b[0m WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=11858)\u001b[0m E0000 00:00:1759231880.087572   11858 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=11858)\u001b[0m E0000 00:00:1759231880.095609   11858 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
            "\u001b[36m(pid=11858)\u001b[0m W0000 00:00:1759231880.115361   11858 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m             This is a deprecated feature. It will be removed\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m             entirely in future versions of Flower.\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m   warnings.warn(warn_msg)\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=11864) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m   self.pid = os.fork()\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m /usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m   warnings.warn(warn_msg)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m /usr/lib/python3.12/multiprocessing/popen_fork.py:66: DeprecationWarning: This process (pid=11863) is multi-threaded, use of fork() may lead to deadlocks in the child.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m   self.pid = os.fork()\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11862)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11863)\u001b[0m         \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m \n",
            "\u001b[36m(ClientAppActor pid=11864)\u001b[0m         \n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 13.21s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 1.4473384221394856\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 5.1335428555806475\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 1.0319629907608032\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'val_accuracy': [(1, 0.75), (2, 0.25), (3, 0.75)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'val_loss': [(1, 1.4473384221394856),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 5.1335428555806475),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 1.0319629907608032)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. Check `history` for results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 7 â€” Summarize metrics per round"
      ],
      "metadata": {
        "id": "H0egANCDaiAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Depending on Flower version, these fields may vary\n",
        "    if hasattr(history, \"metrics_distributed\"):\n",
        "        print(\"Distributed metrics:\", history.metrics_distributed)\n",
        "    if hasattr(history, \"metrics_centralized\"):\n",
        "        print(\"Centralized metrics:\", history.metrics_centralized)\n",
        "    if hasattr(history, \"losses_distributed\"):\n",
        "        print(\"Distributed losses:\", history.losses_distributed)\n",
        "except Exception as e:\n",
        "    print(\"Could not summarize history:\", repr(e))\n"
      ],
      "metadata": {
        "id": "Gc5xgn1KQ-hR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "872f7eb3-87bb-4622-aec8-5ec30873ef92"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distributed metrics: {'val_loss': [(1, 1.4473384221394856), (2, 5.1335428555806475), (3, 1.0319629907608032)], 'val_accuracy': [(1, 0.75), (2, 0.25), (3, 0.75)]}\n",
            "Centralized metrics: {}\n",
            "Distributed losses: [(1, 1.4473384221394856), (2, 5.1335428555806475), (3, 1.0319629907608032)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CwQg4t_LZB0s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}